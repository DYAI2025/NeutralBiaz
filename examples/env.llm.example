# LLM Configuration Example
# Copy this file to .env and configure your API keys

# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Default LLM provider (openai, anthropic, azure, google)
LLM_DEFAULT_PROVIDER=anthropic

# =============================================================================
# OpenAI Configuration
# =============================================================================
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL=gpt-4
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.1

# =============================================================================
# Anthropic Configuration
# =============================================================================
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_BASE_URL=https://api.anthropic.com/v1
ANTHROPIC_MODEL=claude-3-sonnet-20240229
ANTHROPIC_MAX_TOKENS=4096
ANTHROPIC_TEMPERATURE=0.1

# =============================================================================
# Azure OpenAI Configuration
# =============================================================================
AZURE_OPENAI_API_KEY=your-azure-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=your-deployment-name
AZURE_MAX_TOKENS=4096
AZURE_TEMPERATURE=0.1

# =============================================================================
# Google AI Configuration
# =============================================================================
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_PROJECT_ID=your-project-id
GOOGLE_MODEL=gemini-pro
GOOGLE_MAX_TOKENS=4096
GOOGLE_TEMPERATURE=0.1

# =============================================================================
# Rate Limiting Configuration
# =============================================================================
LLM_RATE_LIMIT_ENABLED=true
LLM_RATE_LIMIT_RPM=60
LLM_RATE_LIMIT_TPM=100000
LLM_RATE_LIMIT_BURST=10

# =============================================================================
# Request Configuration
# =============================================================================
LLM_REQUEST_TIMEOUT=60
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0

# =============================================================================
# Prompt Configuration
# =============================================================================
LLM_PROMPTS_FILE=config/prompts.yaml
LLM_PROMPTS_CACHE_ENABLED=true

# =============================================================================
# Quality and Validation Settings
# =============================================================================
LLM_RESPONSE_VALIDATION=true
LLM_FALLBACK_ENABLED=true
LLM_QUALITY_THRESHOLD=0.7

# =============================================================================
# Logging Configuration
# =============================================================================
LLM_LOG_REQUESTS=true
LLM_LOG_RESPONSES=false  # Set to false for privacy
LLM_LOG_TOKENS=true

# =============================================================================
# Cultural Context Configuration
# =============================================================================
CULTURAL_PROFILES_ENABLED=true
DEFAULT_CULTURAL_PROFILE=neutral

# =============================================================================
# Application Settings (existing)
# =============================================================================
APP_NAME=Bias Engine API
APP_VERSION=1.0.0
DEBUG=false
ENVIRONMENT=production

HOST=0.0.0.0
PORT=8000

SECRET_KEY=your-secret-key-here-make-it-very-long-and-secure
ALLOWED_HOSTS=localhost,127.0.0.1,your-domain.com
CORS_ORIGINS=http://localhost:3000,https://your-frontend-domain.com

# =============================================================================
# Database Configuration (existing)
# =============================================================================
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=your-redis-password
REDIS_DB=0

# =============================================================================
# Model Configuration (existing)
# =============================================================================
DEFAULT_MODEL=distilbert-base-uncased
MODELS_CACHE_DIR=./models
MAX_MODEL_CACHE_SIZE=5

# =============================================================================
# API Configuration (existing)
# =============================================================================
MAX_REQUEST_SIZE=10485760
REQUEST_TIMEOUT=30
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# =============================================================================
# Bias Detection Configuration (existing)
# =============================================================================
BIAS_THRESHOLD=0.7
CONFIDENCE_THRESHOLD=0.8
SUPPORTED_LANGUAGES=en,de,es,fr

# =============================================================================
# Logging Configuration (existing)
# =============================================================================
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=logs/bias-engine.log