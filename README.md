# BiazNeutralize AI - Advanced Bias Detection Engine

A comprehensive bias detection engine with intersectional taxonomy support, designed for identifying and analyzing bias across multiple dimensions including demographic, cultural, socioeconomic, and intersectional factors.

## ğŸ¯ Features

### Core Capabilities
- **ğŸ§  Intersectional Bias Detection**: Advanced analysis of overlapping and interconnected social identities
- **ğŸ”§ Hybrid Detection Methods**: Combines rule-based patterns, ML classification, and transformer models
- **ğŸŒ Multilingual Support**: English and German with extensible architecture for 100+ languages
- **ğŸ“Š Sophisticated Scoring**: Confidence estimation and severity calculation with cultural adaptation
- **âš¡ High Performance**: Optimized for accuracy and speed with memory management

### Bias Taxonomy (9+ Core Families)
1. **Cognitive Bias**: Confirmation, anchoring, availability heuristics
2. **Demographic Bias**: Age, gender, racial, sexual orientation
3. **Socioeconomic Bias**: Class, education, occupation
4. **Cultural Bias**: Nationality, religious, linguistic
5. **Physical Bias**: Appearance, disability, health status
6. **Institutional Bias**: Systemic, algorithmic
7. **Temporal Bias**: Historical, generational
8. **Ideological Bias**: Political, moral
9. **Intersectional Bias**: Multiple identity, identity erasure

### Technical Architecture
- **Rule-Based Engine**: 200+ specialized patterns with contextual analysis
- **ML Classification**: Ensemble of transformer models (BERT/DistilBERT), traditional ML, and hate speech detection
- **NLP Pipeline**: spaCy, transformers, FastText integration with language detection
- **Scoring Algorithms**: Bayesian confidence aggregation, cultural-adaptive severity, uncertainty quantification
- **Memory Management**: Intelligent caching, cleanup, and performance optimization

## ğŸš€ Quick Start

### Installation

```bash
git clone https://github.com/your-org/BiazNeutralize_AI.git
cd BiazNeutralize_AI
pip install -r requirements.txt

# Install spaCy models
python -m spacy download en_core_web_sm
python -m spacy download de_core_news_sm
```

### Basic Usage

```python
from src.bias_engine import detect_bias_spans

# Simple bias detection
text = "Women are naturally more emotional than men."
results = detect_bias_spans(text)

if results and results[0].detected_spans:
    result = results[0]
    print(f"Overall Severity: {result.overall_severity:.2f}/10")
    print(f"Overall Confidence: {result.overall_confidence:.2f}")
    
    for span in result.detected_spans:
        print(f"Bias: '{span.text}' -> {span.bias_family}.{span.bias_subtype}")
        print(f"Severity: {span.severity:.2f}, Confidence: {span.confidence:.2f}")
```

### Advanced Configuration

```python
from src.bias_engine import get_detection_engine, DetectionConfig

# Custom configuration
config = DetectionConfig(
    enable_rule_based=True,
    enable_ml_classification=True,
    enable_intersectional_analysis=True,
    confidence_threshold=0.3,
    severity_threshold=2.0,
    max_spans_per_text=50,
    cultural_adaptation=True
)

engine = get_detection_engine(config)
results = engine.detect_bias_spans(
    "Complex text with multiple bias types...",
    language="auto"
)
```

### Intersectional Analysis

```python
text = "Young women from minority backgrounds are not suited for tech leadership."
results = detect_bias_spans(text)

if results and results[0].intersectional_analysis:
    ia = results[0].intersectional_analysis
    print(f"Detected Identities: {ia.detected_identities}")
    print(f"Amplification Factor: {ia.amplification_factor:.2f}")
    print(f"Marginalization Indicators: {ia.marginalization_indicators}")
```

### JSON Output

```python
results = detect_bias_spans("Biased text here...")
if results:
    json_output = results[0].to_json(indent=2)
    print(json_output)
```

## ğŸ“Š API Reference

### Core Functions

#### `detect_bias_spans(text: str, language: str = "auto") -> List[BiasDetectionResult]`
Main function for bias detection.

**Parameters:**
- `text`: Input text to analyze
- `language`: Language code ("en", "de", "auto")

**Returns:** List of detection results with spans, scores, and metadata

#### `classify_bias_type(span: str, context: str) -> BiasClassification`
Classify bias type for a specific span.

#### `calculate_severity(bias_type: str, span: str) -> float`
Calculate severity score (0-10) for a bias type.

#### `calculate_confidence(detection_signals: List) -> float`
Calculate confidence score (0-1) from detection signals.

### Data Models

#### `BiasDetectionResult`
```python
@dataclass
class BiasDetectionResult:
    id: str
    text: str
    language: str
    detected_spans: List[BiasSpan]
    overall_severity: float
    overall_confidence: float
    intersectional_analysis: Optional[IntersectionalAnalysis]
    cultural_context: Dict[str, Any]
    processing_metadata: Dict[str, Any]
    timestamp: datetime
```

#### `BiasSpan`
```python
@dataclass
class BiasSpan:
    start: int
    end: int
    text: str
    bias_family: str
    bias_subtype: str
    severity: float  # 0-10
    confidence: float  # 0-1
    method: DetectionMethod
    explanation: str
    context_window: str
    intersectional_factors: List[str]
```

#### `IntersectionalAnalysis`
```python
@dataclass
class IntersectionalAnalysis:
    detected_identities: List[str]
    intersection_score: float
    amplification_factor: float
    erasure_indicators: List[str]
    privilege_indicators: List[str]
    marginalization_indicators: List[str]
```

## ğŸ§ª Testing

### Run Test Suite

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test modules
python -m pytest tests/bias_engine/test_bias_detection.py -v

# Run with coverage
python -m pytest tests/ --cov=src --cov-report=html
```

### Test Categories
- **Taxonomy Tests**: Bias family loading and validation
- **NLP Pipeline Tests**: Language detection, preprocessing, span extraction
- **Detection Tests**: Rule-based and ML-based bias detection
- **Scoring Tests**: Confidence and severity algorithms
- **Integration Tests**: End-to-end detection pipeline
- **Performance Tests**: Memory management and concurrent processing

### Demo Script

```bash
python scripts/demo_bias_detection.py
```

The demo showcases:
- Basic bias detection on sample texts
- Advanced configuration with intersectional analysis
- JSON output format
- Multilingual support
- Performance metrics

## âš™ï¸ Configuration

### Bias Taxonomy Configuration

Edit `config/bias_families.json` to customize:
- Bias families and subtypes
- Pattern definitions
- Severity multipliers
- Intersectional combinations
- Thresholds

### Model Configuration

```python
from src.bias_engine.config_manager import create_default_config

config = create_default_config()
config.models['custom-bert'] = ModelConfig(
    name='custom-model-name',
    cache_size=1,
    device='auto',
    max_memory_mb=512
)
```

## ğŸ“‹ Performance

### Benchmarks
- **Accuracy**: F1 â‰¥ 0.85 across all bias families
- **Speed**: ~3-5 texts/second (depending on length and complexity)
- **Memory**: Intelligent caching with automatic cleanup
- **Scalability**: Concurrent processing support

### Optimization Features
- Model caching and lazy loading
- Batch processing for multiple texts
- Memory cleanup and garbage collection
- GPU acceleration support (CUDA)

## ğŸŒ Multilingual Support

### Currently Supported
- **English (en)**: Full support with comprehensive patterns
- **German (de)**: Full support with cultural adaptation

### Extensible Architecture
- Language detection via FastText
- Modular NLP pipelines per language
- Cultural adaptation framework
- Easy addition of new languages

### Adding New Languages

1. Add language-specific spaCy model
2. Create language patterns in taxonomy
3. Add cultural profiles (optional)
4. Update configuration

## ğŸ•°ï¸ Cultural Adaptation

### Hofstede Cultural Dimensions
- **Power Distance Index (PDI)**
- **Individualism vs. Collectivism (IDV)**
- **Masculinity vs. Femininity (MAS)**
- **Uncertainty Avoidance Index (UAI)**
- **Long Term Orientation (LTO)**
- **Indulgence vs. Restraint (IVR)**

### Cultural Severity Adjustment
```python
# Automatically adjusts severity based on cultural context
config = DetectionConfig(cultural_adaptation=True)
engine = get_detection_engine(config)

# Bias severity will be adjusted based on sender/receiver culture
results = engine.detect_bias_spans(text, language="de")
```

## ğŸ›¡ï¸ Security & Privacy

### Privacy Features
- No persistent text storage by default
- Hash-based logging for privacy
- Configurable data retention
- GDPR compliance support

### Security Considerations
- Input validation and sanitization
- Safe model loading and execution
- Memory-safe operations
- Error handling without data leakage

## ğŸ“š Documentation

### Project Structure
```
BiazNeutralize_AI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bias_engine/          # Core detection engine
â”‚   â”‚   â”œâ”€â”€ core_detector.py   # Main detection interface
â”‚   â”‚   â”œâ”€â”€ rule_based_detector.py
â”‚   â”‚   â”œâ”€â”€ ml_classifier.py
â”‚   â”‚   â”œâ”€â”€ scoring_algorithms.py
â”‚   â”‚   â”œâ”€â”€ nlp_pipeline.py
â”‚   â”‚   â”œâ”€â”€ taxonomy_loader.py
â”‚   â”‚   â””â”€â”€ config_manager.py
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ bias_models.py     # Data models
â”œâ”€â”€ config/
â”‚   â””â”€â”€ bias_families.json  # Bias taxonomy
â”œâ”€â”€ tests/                  # Comprehensive test suite
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ demo_bias_detection.py
â””â”€â”€ requirements.txt
```

### Key Components

1. **Core Detector**: Main orchestration and API
2. **Rule-Based Engine**: Pattern matching and linguistic rules
3. **ML Classifier**: Ensemble of ML models for classification
4. **Scoring Algorithms**: Confidence and severity calculation
5. **NLP Pipeline**: Text processing and language detection
6. **Taxonomy Loader**: Bias family and pattern management
7. **Config Manager**: Model caching and performance optimization

## ğŸ¤ Contributing

### Development Setup

```bash
git clone https://github.com/your-org/BiazNeutralize_AI.git
cd BiazNeutralize_AI
pip install -r requirements.txt
pip install -e .

# Install development dependencies
pip install black flake8 mypy pytest-cov

# Run code formatting
black src/ tests/
flake8 src/ tests/

# Type checking
mypy src/
```

### Adding New Bias Patterns

1. Edit `config/bias_families.json`
2. Add patterns to appropriate bias family/subtype
3. Test with sample texts
4. Update tests
5. Submit pull request

### Adding New Detection Methods

1. Implement in appropriate module
2. Add to ensemble in `ml_classifier.py`
3. Update scoring algorithms if needed
4. Add comprehensive tests
5. Update documentation

## ğŸ“œ License

MIT License - see LICENSE file for details.

## ğŸ“§ Contact

For questions, issues, or contributions:
- GitHub Issues: [Create an issue](https://github.com/your-org/BiazNeutralize_AI/issues)
- Email: contact@biazneutralize.ai
- Documentation: [Full Documentation](https://docs.biazneutralize.ai)

## ğŸš€ Roadmap

### Current Version (1.0.0)
- Core bias detection engine
- Intersectional analysis
- English and German support
- Rule-based + ML hybrid approach

### Upcoming Features
- Additional cultural models (GLOBE, Hall, Trompenaars)
- 100+ language support
- Real-time API service
- Web dashboard interface
- Fine-tuned bias-specific transformers
- Active learning and model improvement

---

**Built with â¤ï¸ for creating more inclusive and fair AI systems.**
